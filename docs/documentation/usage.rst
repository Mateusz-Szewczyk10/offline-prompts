:html_theme.sidebar_secondary.remove:

Usage
==========

.. seealso::

    - For the streamlined implementation, please refer to :doc:`quickstart`.
    - For the API references (i.e., classes and functions), please refer to :doc:`api`.

This page explains how to set up the full-LLM benchmark using the MovieLens dataset :cite:`` or a custom dataset.

Setting up the full-LLM environment with MovieLens
~~~~~~~~~~

To load the pre-trained simulator, make sure that the path is connected to this repository and the following files are located in a local repository. The following files are available [here]().

- `movielens_preprocessed_data.csv` (preprocessed `MovieLens <https://grouplens.org/datasets/movielens/>`_ :cite:`` dataset)
- `movielens_benchmark_prompts.csv` (candidate prompts)
- `movielens_naive_cf_user_embeddings.pt` (user embeddings)
- `movielens_query.csv` (candidate items (i.e., movies))
- `movielens_distilbert_reward_simulator.pt` (params of the finetuned reward simulator)
- `movielens_prompt_pca_matrix.pt` (PCA matrix which maps prompt embeddings to low-dimensional features) 
- `movielens_query_pca_matrix.pt` (PCA matrix which maps query embeddings to low-dimensional features) 
- `movielens_sentence_pca_matrix.pt` (PCA matrix which maps sentence embeddings to low-dimensional features) 
- `movielens_prompt_embs.pt` (low-dimensional embeddings of prompts)
- `movielens_query_embs.pt` (low-dimensional embeddings of queries)

Then, initialize the full-LLM environment as follows.

.. code-block:: python

    from off_prompts.dataset import SemiSyntheticDataset

    dataset = SemiSyntheticDataset(
        path_to_user_embeddings="{path_to_directory}/movielens_naive_cf_user_embeddings.pt",      # required
        path_to_queries="{path_to_directory}/movielens_query.csv",                                # required
        path_to_query_embeddings="{path_to_directory}/movielens_query_embs.pt",                   # required
        path_to_interaction_data="{path_to_directory}/movielens_preprocessed_data.csv",           # required
        path_to_candidate_prompts="{path_to_directory}/movielens_benchmark_prompts.csv",          # required
        path_to_prompt_embeddings="{path_to_directory}/movielens_prompt_embs.pt",                 # required
        path_to_finetuned_params="{path_to_directory}/movielens_distilbert_reward_simulator.pt",  # required
        frozen_llm_base_model_id="mistralai/Mistral-7B-Instruct-v0.2",
        frozen_llm_base_tokenizer_id="mistralai/Mistral-7B-Instruct-v0.2",
        frozen_llm_use_tokenizer_fast=False,
        frozen_llm_pattern=None,
        reward_simulator_base_model_id="distilbert-base-uncased",
        reward_simulator_base_tokenizer_id="distilbert-base-uncased",
        reward_simulator_use_tokenizer_fast=False,
        reward_type="continuous",  # "binary" or "continuous"
        reward_std=1.0,
        device="cuda",
        random_state=12345,
    )


Note that, to obtain the required dataset, run the following scripts under `offline-prompts/off_prompts/dataset/assets`. The code exection is confirmed with a single or multiple GPUs with 64GB memory. 

(i) Preprocess the MovieLens dataset. 
----------

Before running the code, make sure that the original dataset is downloaded in a local repository from `this page <https://grouplens.org/datasets/movielens/>`_. The default simulation uses MovieLens-10M.

.. code-block:: bash
  
    python preprocess_movielens_dataset_for_reward_simulation.py setting.dataset_name={dataset_name} setting.dataset_dir={path_to_movielens_dataset_directory}


This script saves the preprocessed data to `movielens_preprocessed_data.csv`. The script applies the following preprocessing:

- Binarize the ratings by letting 0-3 to be negative and 5 to be positive.
- Remove users and items that has less than 10 ratings for both positive and negative labels.
- Resample dataset so that the negative and positive labels have the same number of samples for each users.
- Attach item (movie) description generated by a Frozen LLM (`Mistral-7B <https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2>`_ :cite:``. Note that this description is generated without keyword prompts. 

To use other (frozen) LLMs, , use the following command instead. `model_id` and `tokenizer_id` should be those specified by `Huggingface <https://huggingface.co/models>`_ :cite:``, such as `mistralai/Mistral-7B-Instruct-v0.2`.

.. code-block:: bash
  
    python preprocess_movielens_dataset_for_reward_simulation.py setting.dataset_name={dataset_name} setting.dataset_dir={path_to_movielens_dataset_directory} setting.model_id={model_id} setting.

(ii) Retrieve candidate (keyword) prompts. 
----------

Before running the code, make sure that `Beautiful Soup <https://beautiful-soup-4.readthedocs.io/en/latest/>_` :cite:`` is installed.

.. code-block:: bash

    python scraping_prompts.py setting.keywords=\["movie","genre","culture"\]

This scripts collects related words of "movie", "genre", and "culture" from `relatedwords.io <https://relatedwords.io/>`_ and save them in `movielens_benchmark_prompts.csv`.

(iii) Finetune a reward simulator. 
----------

By default, we use `DistilBERT <https://huggingface.co/distilbert/distilbert-base-uncased>`_ :cite:`` as the base model.

.. code-block:: bash

    python finetuning_reward_simulator.py reward_model.dataset_path={path_to_directory}/movielens_preprocessed_data.csv

This script save the finetuned model params to `movielens_distilbert_reward_simulator.pt`. 
This model first encodes the sentence description of each item (movie) to a low-dimensional embeddings and also optimizes the user id embeddings. 
Then, this simulator predicts the binarized rating (i.e., affinity between user and item) via NN model taking the item description embeddings and user id embeddings as inputs.

Note that this script additionally saves the model params of *naive* collaborative filtering (CF) model to `movielens_naive_cf_params.pt`. 
This naive CF model predicts the binarized rating via NN model taking the item id embeddings and user id embeddings as inputs.

Finally, to use other language models to encode sentence descriptions, use the following command instead. 
`based_model_id` and `tokenizer_id` should be those specified by `Huggingface <https://huggingface.co/models>`_ :cite:``, such as `distilbert-base-uncased`.

.. code-block:: bash

    python finetuning_reward_simulator.py reward_model.dataset_path={path_to_directory}/movielens_preprocessed_data.csv reward_model.model_name={model_name} reward_model.base_model_id={base_model_id} reward_model.tokenizer_id={tokenizer_id}

The model params will be saved as `movielens_{model_name}_reward_simulator.pt`.

(iv) Retrieve lists of unique users and items (movie names). 
This code also retrieves user id embeddings for each user.

```bash
python preprocess_movielens_dataset_for_user_query_simulation.py user_query_simulation.dataset_path={path_to_directory}/movielens_preprocessed_data.csv user_query_simulation.model_path={path_to_directory}/movielens_naive_cf_params.pt user_query_simulation.use_naive_cf_user_embs=True
```

The script saves `movielens_naive_cf_user_embeddings.pt` and `movielens_query.csv`. Note that the user id embeddings is based on the naive CF model, which is different from those used for the (sentence-based) reward simulator.

(v) Retrieve prompt embeddings, query embeddings, and PCA matrix of sentence encoders.
----------

.. code-block:: bash

    python preprocess_movielens_dataset_with_embeddings.py encoding.query_path={path_to_directory}/movielens_query.csv encoding.prompt_path={path_to_directory}/movielens_benchmark_prompts.csv encoding.sentence_path={path_to_directory}/movielens_preprocessed_data.csv

The scripts saves the following files.

- `movielens_prompt_pca_matrix.pt` (PCA matrix which maps prompt embeddings to low-dimensional features) 
- `movielens_query_pca_matrix.pt` (PCA matrix which maps query embeddings to low-dimensional features) 
- `movielens_sentence_pca_matrix.pt` (PCA matrix which maps sentence embeddings to low-dimensional features) 
- `movielens_prompt_embs.pt` (low-dimensional embeddings of prompts)
- `movielens_query_embs.pt` (low-dimensional embeddings of queries)

The default prompt/query/sentence embedding model is the (frozen) `Mistral-7B <https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2>`_ :cite:`` model, which is different from those used for the reward simualtor (i.e., `DistilBERT <https://huggingface.co/distilbert/distilbert-base-uncased>`_ :cite:`` in the default setting.) 
To use other frozen LLMs as the embedding models, run the following command instead.

.. code-block:: bash

    python preprocess_movielens_dataset_with_embeddings.py encoding.query_path={path_to_directory}/movielens_query.csv encoding.prompt_path={path_to_directory}/movielens_benchmark_prompts.csv encoding.sentence_path={path_to_directory}/movielens_preprocessed_data.csv encoding.base_model_id={base_model_id} encoding.tokenizer_id={tokenizer_id}


Again, `base_model_id` and `tokenizer_id` should be those specified by `Huggingface <https://huggingface.co/models>`_ :cite:``, such as `mistralai/Mistral-7B-Instruct-v0.2`.


Setting up the full-LLM environment with custom dataset
~~~~~~~~~~

To use the custom dataset, we provide the data format of each file as follows.

Interaction data
----------

This data corresponds to `movielens_preprocessed_data.csv` in the default simulation. The dataset should contain four columns.

- `user_id` (int): index of users
- `item_id` (int): index of items
- `title` (str): name of items (e.g., movie title)
- `description` (str): text description of items (, which is generated by frozen LLM)
- `rating` (float): original or binarized ratings

Candidate prompts
----------

This data corresponds to `movielens_benchmark_prompts.csv` in the default simulation. The dataset should contain a single column.

- `vocab` (str): keyword prompts

While we use short keywords as the candidate prompts by default, the framework is generally applicable to longer sentence prompts.

Queries
----------

This data corresponds to `movielens_benchmark_prompts.csv` in the default simulation. The dataset should contain a single column.

- `query` (str): name of items (e.g., movie title)

Note that this file contains the list of unique items without any duplicates. This should be direct mapping between item id and the item name.

User, query, prompt embeddings
----------

These data correspond to `movielens_naive_cf_user_embeddings.pt`, `movielens_query_embs.pt`, and `movielens_prompt_embs.pt`. Each file contains the following shape of torch.Tensor.

- `user_id_embeddings` (torch.Tensor): Mapping between user id and its embeddings. shape (n_users, dim_user_emb)`
- `query_embeddings` (torch.Tensor): Mapping between item id and its embeddings. shape (n_items, dim_query_emb)
- `prompt_embeddings` (torch.Tensor): Mapping between action (prompt) id and its embeddings. shape (n_actions, dim_prompt_emb)

PCA matrices
----------

These data correspond to `movielens_{query/prompt/sentence}_pca_matrix.pt`. Each matrix is torch.Tensor that represents mappings from high-dimensional features (obtained by the last layer of frozen LLMs) and low-dimensional features. 
Thus, the shape of each Tensor is (dim_frozen_llm_emb, dim_emb).

Reward simulator
----------

By default, the reward simulator consists of the following components:

- `sentence_embedding_layer`: takes sentence description of items as inputs and outputs low-dimensional item embeddings.
- `user_embedding_layer`: takes user id as inputs and outputs the corresponding user embeddings.
- `nn_layer`: takes the above item embeddings and user embeddings as inputs and outputs a logit to predict ratings.

When the data format satisfies the requirement of "Interaction data" (i.e., have `user_id`, `item_id`, `title`, `description`, and `rating`), users can learn a semi-synthetic simulator as follows.

.. code-block:: bash

    python finetuning_reward_simulator.py setting.setting={setting} reward_model.dataset_path={path_to_custom_dataset} 

Then, the results will be saved as `{setting}_distilbert_reward_simulator.pt`. Note that `path_to_custom_dataset` should end with `.csv`.

Citation
~~~~~~~~~~

If you use this simulator in your project or find this resource useful, please cite the following papers.

(package and documentation)

.. card::

    | Haruka Kiyohara, Daniel Yiming Cao, Yuta Saito, Thorsten Joachims
    | **OfflinePrompts: Benchmark Suites for Prompt-guided Language Personalization**
    | (a preprint is coming soon..)

    .. code-block::

        @article{kiyohara2025offline,
            title = {OfflinePrompts: Benchmark Suites for Prompt-guided Language Personalization},
            author = {Kiyohara, Haruka and Cao, Daniel Yiming and Saito, Yuta and Joachims, Thorsten},
            journal = {xxx},
            pages = {xxx--xxx},
            year = {2025},

(benchmarking experiment)

.. card::

    | Haruka Kiyohara, Daniel Yiming Cao, Yuta Saito, Thorsten Joachims
    | **Off-Policy Learning for Prompt-Guided Sentence Personalization Using Logged Bandit Data**

    .. code-block::

        @article{kiyohara2025off,
            title = {Off-Policy Learning for Prompt-Guided Sentence Personalization Using Logged Bandit Data},
            author = {Kiyohara, Haruka and Cao, Daniel Yiming and Saito, Yuta and Joachims, Thorsten},
            journal = {xxx},
            pages = {xxx--xxx},
            year = {2025},
        }

.. raw:: html

  <div class="white-space-20px"></div>

.. grid::
    :margin: 0

    .. grid-item::
        :columns: 3
        :margin: 0
        :padding: 0

        .. grid::
            :margin: 0

            .. grid-item-card::
                :link: quickstart
                :link-type: doc
                :shadow: none
                :margin: 0
                :padding: 0

                <<< Prev
                **Quickstart**

    .. grid-item::
        :columns: 6
        :margin: 0
        :padding: 0

    .. grid-item::
        :columns: 3
        :margin: 0
        :padding: 0

        .. grid::
            :margin: 0

            .. grid-item-card::
                :link: api
                :link-type: doc
                :shadow: none
                :margin: 0
                :padding: 0

                Next >>>
                **API reference**