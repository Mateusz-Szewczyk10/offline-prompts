:html_theme.sidebar_secondary.remove:

OfflinePrompts
===================================

.. raw:: html

    <h3>A Python library and benchmarks for prompt-guided language personalization</h3>
    <div class="white-space-5px"></div>

.. card::
    :width: 75%
    :margin: auto
    :img-background: ../_static/images/logo.png
    :text-align: center

Overview
~~~~~~~~~~
Personalizing sentence generation is crucial in interactive platforms including recommender systems, online ads, and educational apps. 
For example, consider a situation where we recommend the movie "Wall-E (2008)" with some short descriptions or slogans of the movie, as shown in the following figure. 
If the user is a sci-fi lover, the description focusing on the "sci-fi" aspect of the movie would gain more attention than that focusing on the "romance" aspect, and vice versa. Such personalization is crucial for maximizing some business metrics and users' welfare.


.. card::
   :width: 75%
   :margin: auto
   :img-top: ../_static/images/motivate_example.png
   :text-align: center

   Motivative example of for generating personalized sentence in movie recommendation.

.. raw:: html

    <div class="white-space-20px"></div>

This package, called *OfflinePrompt*, aims to provide tools for the above personalization focusing on the prompt-policy learning from logged bandit data. Specifically, we consider the following workflow -- (i) For each coming user, a policy chooses which prompt to use to generate sentences with a frozen LLM. (ii) Each user observes only the sentence generated by the chosen prompt and provides the reward for the corresponding sentence. -- Figure xxx illustrates the interaction process. Through daily operations in the platform, a (logging) policy naturally collects user responses to the sentence generated by the logging policy. Our goal is to use such informative logged data to learn or evaluate a new policy **(Off-policy evaluation and learning; OPE/OPL)** for better personalization in the future. 

.. card::
   :width: 75%
   :margin: auto
   :img-top: ../_static/images/personalized_sentence_generation.png
   :text-align: center

   Prompt-guided sentence personalization as a off-policy learning of contextual bandits. 

.. raw:: html

    <div class="white-space-20px"></div>

To facilitate the research and practical applications of OPL of prompt policies, OfflinePrompts contributes to the followings; 

* To implement representative OPL methods for prompt optimization. 
* To provide two benchmark environments, including synthetic and full-LLM.
* To streamline the workflow to connect OPL and sentence generation modules for smooth experimentation. 

In particular, the provided full-LLM benchmark models realistic users' responses to the presented sentence in the movie recommendation settings, by training a semi-synthetic reward simulator with the sentence-augmented `MovieLens <https://grouplens.org/datasets/movielens/>`_ dataset. The benchmark design is a remarkable contribution to the research community, as we currently lack a realistic simulator on personalized sentence generation tasks that satisfies the following four key qualifications:

* LLMs have knowledge about items (e.g., movies) so that they can generate descriptions.
* Items have more than two aspects (e.g., sci-fi and romance) so that choosing a prompt makes the difference in expected rewards.
* The above \textit{prompt effects} can be different among individual contexts (i.e., users).
* The prompt effects are learnable from datasets, so we can learn a realistic simulator (e.g., MovieLens enables us to learn affinity between user preference and movie features).

We hope this work will be an important cornerstone to the real-world applications of OPL for prompt-guided language personalization!

Implementation
~~~~~~~~~~
OfflinePrompts enables streamlined implementation of interaction simulation, data collection, and off-policy learning (OPL). 
OfflinePrompts can also handle semi-synthetic experiments using recommendation datasets, such as `MovieLens <https://grouplens.org/datasets/movielens/>`_ :cite:`harper2015movielens` and is compatible to `HuggingFace <https://huggingface.co/>`_ :cite:`wolf2019huggingface` language models.

Simulations and Data Collection Policy
----------

Dataset class
^^^^^^
* SemisyntheticDataset
* SyntheticDataset

Support classes
^^^^^^
* FrozenLLM
* RewardSimulator

Policy
^^^^^^

* (abstract base)
* Two Stage
* Epsilon Greedy
* Softmax


Off-Policy Evaluation and Learning (OPE/L)
----------

Learning methods
^^^^^^
* REINFORCE (online) :cite:`williams1992simple`
* Actor-critic :cite:`konda1999actor`
* Importance Sampling (IS) :cite:`swaminathan2015batch`
* Doubly Robust (DR) :cite:`dudik2014doubly`
* POTEC :cite:`saito2024potec`
* DSO (our proposal) :cite:`kiyohara2025off`

Corresponding evaluation methods
^^^^^^
* (online)
* Direct Method (DM) :cite:`beygelzimer2009offset`
* Importance Sampling (IS) :cite:`strehl2010learning`
* Doubly Robust (DR) :cite:`dudik2014doubly`
* OffCEM :cite:`saito2023off`
* Kernel IS (our proposal) :cite:`kiyohara2025offline`



Citation
~~~~~~~~~~

If you use our pipeline in your work, please cite our paper below.

.. card::

    | Haruka Kiyohara, Daniel Yiming Cao, Yuta Saito, Thorsten Joachims
    | **OfflinePrompts: Benchmark Suites for Prompt-guided Text Personalization from Logged Data**
    | (a preprint is coming soon..)

    .. code-block::

        @article{kiyohara2025offline,
            title = {OfflinePrompts: Benchmark Suites for Prompt-guided Text Personalization from Logged Data},
            author = {Kiyohara, Haruka and Cao, Daniel Yiming and Saito, Yuta and Joachims, Thorsten},
            journal = {arXiv preprint arXiv:},
            year = {2025},
        }

If you use the proposed method (DSO) or refer to our findings in your work, please cite our paper below.

.. card::

    | Haruka Kiyohara, Daniel Yiming Cao, Yuta Saito, Thorsten Joachims
    | **An Off-Policy Learning Approach for Steering Sentence Generation towards Personalization**

    .. code-block::

        @inproceedings{kiyohara2025off,
            title = {An Off-Policy Learning Approach for Steering Sentence Generation towards Personalization},
            author = {Kiyohara, Haruka and Cao, Daniel Yiming and Saito, Yuta and Joachims, Thorsten},
            booktitle = {Proceedings of the 19th ACM Conference on Recommender Systems},
            pages = {xxx--xxx},
            year = {2025},
        }

Note that the above projects were supported in part by NSF Awards IIS-2312865 and OAC-2311521. 
Haruka Kiyohara and Yuta Saito are supported by `Funai Overseas Scholarship <https://funaifoundation.jp/scholarship/en/scholarship_guidelines_phd.html>`_.

Contact
~~~~~~~~~~
For any questions about the paper and pipeline, feel free to contact: hk844@cornell.edu

Contribution
~~~~~~~~~~
Any contributions to OfflinePrompts are more than welcome!
Please refer to `CONTRIBUTING.md <https://github.com/aiueola/offline-prompts/CONTRIBUTING.md>`_ for general guidelines on how to contribute to the project.

Table of Contents
~~~~~~~~~~

.. toctree::
   :maxdepth: 3
   :caption: Getting Started:

   installation
   distinctive_features
   implementations
   dso
   quickstart
   api

.. toctree::
   :maxdepth: 1
   :caption: See also:

   Github <https://github.com/hakuhodo-technologies/scope-rl>
   LICENSE <https://github.com/hakuhodo-technologies/scope-rl/blob/main/LICENSE>
   frequently_asked_questions
   News <news>
   Release Notes <https://github.com/aiueola/offline-prompts/releases>
   Proceedings <https://github.com/aiueola/offline-prompts/404>
   references

.. grid::
    :margin: 0

    .. grid-item::
        :columns: 3
        :margin: 0
        :padding: 0

    .. grid-item::
        :columns: 6
        :margin: 0
        :padding: 0

    .. grid-item::
        :columns: 3
        :margin: 0
        :padding: 0

        .. grid::
            :margin: 0

            .. grid-item-card::
                :link: distinctive_features
                :link-type: doc
                :shadow: none
                :margin: 0
                :padding: 0

                Next >>>
                **Why OfflinePrompts?**

            .. grid-item-card::
                :link: /documentation/quickstart
                :link-type: doc
                :shadow: none
                :margin: 0
                :padding: 0

                Next >>>
                **Quickstart**