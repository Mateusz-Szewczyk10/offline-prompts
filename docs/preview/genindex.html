<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Index &mdash; OfflinePrompts</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
      <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
      <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/tabs.js"></script>
        <script src="_static/design-tabs.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="search" type="application/opensearchdescription+xml"
          title="Search within OfflinePrompts"
          href="_static/opensearch.xml"/>
    <link rel="index" title="Index" href="#" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            OfflinePrompts
          </a>
              <div class="version">
                latest
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="documentation/opl_for_prompts.html">Off-policy learning for prompt-guided language generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="documentation/overview.html">Overview of the software</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="documentation/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="documentation/quickstart.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package References:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="documentation/offline_prompts_api.html">OfflinePrompts API reference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">See also:</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/aiueola/opl-prompt">Github</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/aiueola/opl-prompt/blob/main/LICENSE">LICENSE</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/aiueola/opl-prompt/releases">Release Notes</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/aiueola/opl-prompt/404">Proceedings</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OfflinePrompts</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Index</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             

<h1 id="index">Index</h1>

<div class="genindex-jumpbox">
 <a href="#A"><strong>A</strong></a>
 | <a href="#B"><strong>B</strong></a>
 | <a href="#C"><strong>C</strong></a>
 | <a href="#D"><strong>D</strong></a>
 | <a href="#E"><strong>E</strong></a>
 | <a href="#F"><strong>F</strong></a>
 | <a href="#G"><strong>G</strong></a>
 | <a href="#H"><strong>H</strong></a>
 | <a href="#I"><strong>I</strong></a>
 | <a href="#K"><strong>K</strong></a>
 | <a href="#L"><strong>L</strong></a>
 | <a href="#M"><strong>M</strong></a>
 | <a href="#N"><strong>N</strong></a>
 | <a href="#O"><strong>O</strong></a>
 | <a href="#P"><strong>P</strong></a>
 | <a href="#R"><strong>R</strong></a>
 | <a href="#S"><strong>S</strong></a>
 | <a href="#T"><strong>T</strong></a>
 | <a href="#U"><strong>U</strong></a>
 | <a href="#X"><strong>X</strong></a>
 | <a href="#Z"><strong>Z</strong></a>
 
</div>
<h2 id="A">A</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/toy.opl.reward_learner.ActionRewardLearner.html#toy.opl.reward_learner.ActionRewardLearner">ActionRewardLearner (class in toy.opl.reward_learner)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.ActionRewardLearner">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.add_module">add_module() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.add_module">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.add_module">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.add_module">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.add_module">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.add_module">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.add_module">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.add_module">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.add_module">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.add_module">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.add_module">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.add_module">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.add_module">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.add_module">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.add_module">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.apply">apply() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.apply">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.apply">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.apply">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.apply">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.apply">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.apply">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.apply">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.apply">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.apply">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.apply">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.apply">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.apply">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.apply">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.apply">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.frozen_llm.html#src.dataset.frozen_llm.AutoFrozenLLM">AutoFrozenLLM (class in src.dataset.frozen_llm)</a>
</li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.AuxiliaryOutputGenerator.html#toy.dataset.function.AuxiliaryOutputGenerator">AuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.AuxiliaryOutputGenerator">[1]</a>
</li>
  </ul></td>
</tr></table>

<h2 id="B">B</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel">BaseActionPolicyModel (class in toy.policy.base)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionPolicyModel">[1]</a>
</li>
      <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel">BaseActionRewardModel (class in toy.policy.base)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionRewardModel">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseCandidateActionsLoader.html#src.dataset.base.BaseCandidateActionsLoader">BaseCandidateActionsLoader (class in src.dataset.base)</a>, <a href="documentation/_autosummary/dataset/src.dataset.base.html#src.dataset.base.BaseCandidateActionsLoader">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusteringModel">BaseClusteringModel (class in src.policy.base)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel">(class in toy.policy.base)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusteringModel">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusterPolicyModel">BaseClusterPolicyModel (class in src.policy.base)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel">(class in toy.policy.base)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusterPolicyModel">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseContextQueryLoader.html#src.dataset.base.BaseContextQueryLoader">BaseContextQueryLoader (class in src.dataset.base)</a>, <a href="documentation/_autosummary/dataset/src.dataset.base.html#src.dataset.base.BaseContextQueryLoader">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseEncoder">BaseEncoder (class in src.policy.base)</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseFrozenLLM.html#src.dataset.base.BaseFrozenLLM">BaseFrozenLLM (class in src.dataset.base)</a>, <a href="documentation/_autosummary/dataset/src.dataset.base.html#src.dataset.base.BaseFrozenLLM">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseKernelMarginalDensityModel">BaseKernelMarginalDensityModel (class in src.policy.base)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel">(class in toy.policy.base)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseKernelMarginalDensityModel">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel">BaseOutputRewardModel (class in toy.policy.base)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseOutputRewardModel">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePolicy">BasePolicy (class in src.policy.base)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BasePolicy.html#toy.policy.base.BasePolicy">(class in toy.policy.base)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BasePolicy">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BasePromptFormatter.html#src.dataset.base.BasePromptFormatter">BasePromptFormatter (class in src.dataset.base)</a>, <a href="documentation/_autosummary/dataset/src.dataset.base.html#src.dataset.base.BasePromptFormatter">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptPolicyModel">BasePromptPolicyModel (class in src.policy.base)</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptRewardModel">BasePromptRewardModel (class in src.policy.base)</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator">BaseRewardSimulator (class in src.dataset.base)</a>, <a href="documentation/_autosummary/dataset/src.dataset.base.html#src.dataset.base.BaseRewardSimulator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseSentenceRewardModel">BaseSentenceRewardModel (class in src.policy.base)</a>
</li>
      <li><a href="documentation/_autosummary/src.opl.behavior_cloning.html#src.opl.behavior_cloning.BehaviorCloningLearner">BehaviorCloningLearner (class in src.opl.behavior_cloning)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.behavior_cloning.BehaviorCloningLearner.html#toy.opl.behavior_cloning.BehaviorCloningLearner">(class in toy.opl.behavior_cloning)</a>, <a href="documentation/_autosummary/toy.opl.behavior_cloning.html#toy.opl.behavior_cloning.BehaviorCloningLearner">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.bfloat16">bfloat16() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.bfloat16">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.bfloat16">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.bfloat16">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.bfloat16">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.bfloat16">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.bfloat16">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.bfloat16">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.bfloat16">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.bfloat16">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.bfloat16">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.bfloat16">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.bfloat16">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.bfloat16">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.bfloat16">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.buffers">buffers() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.buffers">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.buffers">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.buffers">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.buffers">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.buffers">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.buffers">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.buffers">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.buffers">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.buffers">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.buffers">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.buffers">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.buffers">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.buffers">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.buffers">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="C">C</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusterPolicyModel.calc_action_choice_probability">calc_action_choice_probability() (src.policy.base.BaseClusterPolicyModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePolicy.calc_action_choice_probability">(src.policy.base.BasePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptPolicyModel.calc_action_choice_probability">(src.policy.base.BasePromptPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.EpsilonGreedyPolicy.calc_action_choice_probability">(src.policy.policy.EpsilonGreedyPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.SoftmaxPolicy.calc_action_choice_probability">(src.policy.policy.SoftmaxPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.TwoStagePolicy.calc_action_choice_probability">(src.policy.policy.TwoStagePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.UniformRandomPolicy.calc_action_choice_probability">(src.policy.policy.UniformRandomPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.calc_action_choice_probability">(toy.policy.base.BaseActionPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionPolicyModel.calc_action_choice_probability">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.calc_action_choice_probability">(toy.policy.base.BaseClusterPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusterPolicyModel.calc_action_choice_probability">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BasePolicy.html#toy.policy.base.BasePolicy.calc_action_choice_probability">(toy.policy.base.BasePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BasePolicy.calc_action_choice_probability">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.calc_action_choice_probability">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.calc_action_choice_probability">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.EpsilonGreedyPolicy.html#toy.policy.policy.EpsilonGreedyPolicy.calc_action_choice_probability">(toy.policy.policy.EpsilonGreedyPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.EpsilonGreedyPolicy.calc_action_choice_probability">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.SoftmaxPolicy.html#toy.policy.policy.SoftmaxPolicy.calc_action_choice_probability">(toy.policy.policy.SoftmaxPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.SoftmaxPolicy.calc_action_choice_probability">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.TwoStagePolicy.html#toy.policy.policy.TwoStagePolicy.calc_action_choice_probability">(toy.policy.policy.TwoStagePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.TwoStagePolicy.calc_action_choice_probability">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.UniformRandomPolicy.html#toy.policy.policy.UniformRandomPolicy.calc_action_choice_probability">(toy.policy.policy.UniformRandomPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.UniformRandomPolicy.calc_action_choice_probability">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusteringModel.calc_cluster_choice_prob">calc_cluster_choice_prob() (src.policy.base.BaseClusteringModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.calc_cluster_choice_prob">(toy.policy.base.BaseClusteringModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusteringModel.calc_cluster_choice_prob">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.calc_cluster_choice_prob">(toy.policy.model.KmeansActionClustering method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusteringModel.calc_cluster_variance">calc_cluster_variance() (src.policy.base.BaseClusteringModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.calc_cluster_variance">(toy.policy.base.BaseClusteringModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusteringModel.calc_cluster_variance">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.calc_cluster_variance">(toy.policy.model.KmeansActionClustering method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.benchmark.SemiSyntheticDataset.html#src.dataset.benchmark.SemiSyntheticDataset.calc_expected_policy_value">calc_expected_policy_value() (src.dataset.benchmark.SemiSyntheticDataset method)</a>, <a href="documentation/_autosummary/dataset/src.dataset.benchmark.html#src.dataset.benchmark.SemiSyntheticDataset.calc_expected_policy_value">[1]</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.synthetic.SyntheticDataset.html#toy.dataset.synthetic.SyntheticDataset.calc_expected_policy_value">(toy.dataset.synthetic.SyntheticDataset method)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.synthetic.html#toy.dataset.synthetic.SyntheticDataset.calc_expected_policy_value">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.calc_expected_reward">calc_expected_reward() (src.dataset.base.BaseRewardSimulator method)</a>, <a href="documentation/_autosummary/dataset/src.dataset.base.html#src.dataset.base.BaseRewardSimulator.calc_expected_reward">[1]</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.calc_expected_reward">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>, <a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.calc_expected_reward">[1]</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.calc_expected_reward">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>, <a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.calc_expected_reward">[1]</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.RewardSimulator.html#toy.dataset.function.RewardSimulator.calc_expected_reward">(toy.dataset.function.RewardSimulator method)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.RewardSimulator.calc_expected_reward">[1]</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.SparseRewardSimulator.html#toy.dataset.function.SparseRewardSimulator.calc_expected_reward">(toy.dataset.function.SparseRewardSimulator method)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.SparseRewardSimulator.calc_expected_reward">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.synthetic.SyntheticDataset.html#toy.dataset.synthetic.SyntheticDataset.calc_expected_reward_for_all_actions">calc_expected_reward_for_all_actions() (toy.dataset.synthetic.SyntheticDataset method)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.synthetic.html#toy.dataset.synthetic.SyntheticDataset.calc_expected_reward_for_all_actions">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.synthetic.SyntheticDataset.html#toy.dataset.synthetic.SyntheticDataset.calc_expected_reward_given_action">calc_expected_reward_given_action() (toy.dataset.synthetic.SyntheticDataset method)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.synthetic.html#toy.dataset.synthetic.SyntheticDataset.calc_expected_reward_given_action">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusterPolicyModel.calc_logits">calc_logits() (src.policy.base.BaseClusterPolicyModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptPolicyModel.calc_logits">(src.policy.base.BasePromptPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.calc_logits">(toy.policy.base.BaseActionPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionPolicyModel.calc_logits">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.calc_logits">(toy.policy.base.BaseClusterPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusterPolicyModel.calc_logits">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.calc_logits">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.calc_logits">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseKernelMarginalDensityModel.calc_pairwise_distance">calc_pairwise_distance() (src.policy.base.BaseKernelMarginalDensityModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.KernelMarginalDensityEstimator.calc_pairwise_distance">(src.policy.model.KernelMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.calc_pairwise_distance">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseKernelMarginalDensityModel.calc_pairwise_distance">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.calc_pairwise_distance">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>, <a href="documentation/_autosummary/toy.policy.model.html#toy.policy.model.NeuralMarginalDensityEstimator.calc_pairwise_distance">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseKernelMarginalDensityModel.calc_pairwise_weight">calc_pairwise_weight() (src.policy.base.BaseKernelMarginalDensityModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.calc_pairwise_weight">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseKernelMarginalDensityModel.calc_pairwise_weight">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.calc_pairwise_weight">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusterPolicyModel.calc_prob_given_action">calc_prob_given_action() (src.policy.base.BaseClusterPolicyModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePolicy.calc_prob_given_action">(src.policy.base.BasePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptPolicyModel.calc_prob_given_action">(src.policy.base.BasePromptPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.EpsilonGreedyPolicy.calc_prob_given_action">(src.policy.policy.EpsilonGreedyPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.SoftmaxPolicy.calc_prob_given_action">(src.policy.policy.SoftmaxPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.TwoStagePolicy.calc_prob_given_action">(src.policy.policy.TwoStagePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.UniformRandomPolicy.calc_prob_given_action">(src.policy.policy.UniformRandomPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.calc_prob_given_action">(toy.policy.base.BaseActionPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionPolicyModel.calc_prob_given_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.calc_prob_given_action">(toy.policy.base.BaseClusterPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusterPolicyModel.calc_prob_given_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BasePolicy.html#toy.policy.base.BasePolicy.calc_prob_given_action">(toy.policy.base.BasePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BasePolicy.calc_prob_given_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.calc_prob_given_action">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.calc_prob_given_action">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.EpsilonGreedyPolicy.html#toy.policy.policy.EpsilonGreedyPolicy.calc_prob_given_action">(toy.policy.policy.EpsilonGreedyPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.EpsilonGreedyPolicy.calc_prob_given_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.SoftmaxPolicy.html#toy.policy.policy.SoftmaxPolicy.calc_prob_given_action">(toy.policy.policy.SoftmaxPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.SoftmaxPolicy.calc_prob_given_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.TwoStagePolicy.html#toy.policy.policy.TwoStagePolicy.calc_prob_given_action">(toy.policy.policy.TwoStagePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.TwoStagePolicy.calc_prob_given_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.UniformRandomPolicy.html#toy.policy.policy.UniformRandomPolicy.calc_prob_given_action">(toy.policy.policy.UniformRandomPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.UniformRandomPolicy.calc_prob_given_action">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.CandidateActionsGenerator.html#toy.dataset.function.CandidateActionsGenerator">CandidateActionsGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.CandidateActionsGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.utils.html#src.utils.check_logged_feedback">check_logged_feedback() (in module src.utils)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.utils.check_logged_feedback.html#toy.utils.check_logged_feedback">(in module toy.utils)</a>, <a href="documentation/_autosummary/toy.utils.html#toy.utils.check_logged_feedback">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.utils.html#src.utils.check_tensor">check_tensor() (in module src.utils)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.utils.check_tensor.html#toy.utils.check_tensor">(in module toy.utils)</a>, <a href="documentation/_autosummary/toy.utils.html#toy.utils.check_tensor">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.children">children() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.children">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.children">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.children">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.children">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.children">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.children">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.children">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.children">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.children">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.children">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.children">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.children">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.children">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.children">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.ClusterPolicy">ClusterPolicy (class in src.policy.model)</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator">CollaborativeFilteringRewardSimulator (class in src.dataset.reward_simulator)</a>, <a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.compile">compile() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.compile">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.compile">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.compile">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.compile">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.compile">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.compile">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.compile">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.compile">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.compile">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.compile">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.compile">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.compile">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.compile">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.compile">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ConfoundedAuxiliaryOutputGenerator.html#toy.dataset.function.ConfoundedAuxiliaryOutputGenerator">ConfoundedAuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.ConfoundedAuxiliaryOutputGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ConfoundedExponentialAuxiliaryOutputGenerator.html#toy.dataset.function.ConfoundedExponentialAuxiliaryOutputGenerator">ConfoundedExponentialAuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.ConfoundedExponentialAuxiliaryOutputGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ConfoundedPowerAuxiliaryOutputGenerator.html#toy.dataset.function.ConfoundedPowerAuxiliaryOutputGenerator">ConfoundedPowerAuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.ConfoundedPowerAuxiliaryOutputGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ConfoundedRationalAuxiliaryOutputGenerator.html#toy.dataset.function.ConfoundedRationalAuxiliaryOutputGenerator">ConfoundedRationalAuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.ConfoundedRationalAuxiliaryOutputGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ConfoundedTrigonometricAuxiliaryOutputGenerator.html#toy.dataset.function.ConfoundedTrigonometricAuxiliaryOutputGenerator">ConfoundedTrigonometricAuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.ConfoundedTrigonometricAuxiliaryOutputGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ContextQueryGenerator.html#toy.dataset.function.ContextQueryGenerator">ContextQueryGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.ContextQueryGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.cpu">cpu() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.cpu">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.cpu">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.cpu">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.cpu">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.cpu">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.cpu">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.cpu">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.cpu">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.cpu">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.cpu">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.cpu">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.cpu">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.cpu">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.cpu">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.cuda">cuda() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.cuda">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.cuda">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.cuda">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.cuda">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.cuda">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.cuda">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.cuda">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.cuda">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.cuda">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.cuda">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.cuda">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.cuda">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.cuda">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.cuda">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="D">D</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.function.DefaultCandidateActionsLoader.html#src.dataset.function.DefaultCandidateActionsLoader">DefaultCandidateActionsLoader (class in src.dataset.function)</a>, <a href="documentation/_autosummary/dataset/src.dataset.function.html#src.dataset.function.DefaultCandidateActionsLoader">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.function.DefaultContextQueryLoader.html#src.dataset.function.DefaultContextQueryLoader">DefaultContextQueryLoader (class in src.dataset.function)</a>, <a href="documentation/_autosummary/dataset/src.dataset.function.html#src.dataset.function.DefaultContextQueryLoader">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.utils.html#src.utils.defaultdict_to_dict">defaultdict_to_dict() (in module src.utils)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.utils.defaultdict_to_dict.html#toy.utils.defaultdict_to_dict">(in module toy.utils)</a>, <a href="documentation/_autosummary/toy.utils.html#toy.utils.defaultdict_to_dict">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.double">double() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.double">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.double">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.double">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.double">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.double">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.double">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.double">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.double">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.double">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.double">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.double">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.double">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.double">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.double">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="E">E</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseEncoder.encode">encode() (src.policy.base.BaseEncoder method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.TransformerEncoder.encode">(src.policy.model.TransformerEncoder method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.EpsilonGreedyPolicy">EpsilonGreedyPolicy (class in src.policy.policy)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.policy.EpsilonGreedyPolicy.html#toy.policy.policy.EpsilonGreedyPolicy">(class in toy.policy.policy)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.EpsilonGreedyPolicy">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseKernelMarginalDensityModel.estimate_marginal_density">estimate_marginal_density() (src.policy.base.BaseKernelMarginalDensityModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.estimate_marginal_density">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseKernelMarginalDensityModel.estimate_marginal_density">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.estimate_marginal_density">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.eval">eval() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.eval">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.eval">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.eval">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.eval">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.eval">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.eval">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.eval">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.eval">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.eval">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.eval">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.eval">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.eval">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.eval">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.eval">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ExponentialAuxiliaryOutputGenerator.html#toy.dataset.function.ExponentialAuxiliaryOutputGenerator">ExponentialAuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.ExponentialAuxiliaryOutputGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.extra_repr">extra_repr() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.extra_repr">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.extra_repr">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.extra_repr">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.extra_repr">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.extra_repr">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.extra_repr">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.extra_repr">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.extra_repr">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.extra_repr">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.extra_repr">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.extra_repr">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.extra_repr">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.extra_repr">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.extra_repr">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="F">F</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.TransformerEncoder.fit_pca">fit_pca() (src.policy.model.TransformerEncoder method)</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.float">float() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.float">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.float">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.float">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.float">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.float">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.float">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.float">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.float">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.float">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.float">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.float">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.float">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.float">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.float">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BasePromptFormatter.html#src.dataset.base.BasePromptFormatter.format_tokens">format_tokens() (src.dataset.base.BasePromptFormatter method)</a>, <a href="documentation/_autosummary/dataset/src.dataset.base.html#src.dataset.base.BasePromptFormatter.format_tokens">[1]</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.prompt_formatter.html#src.dataset.prompt_formatter.MovielensPromptFormatter.format_tokens">(src.dataset.prompt_formatter.MovielensPromptFormatter method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.utils.html#src.utils.FrozenLLMDataset">FrozenLLMDataset (class in src.utils)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="G">G</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.utils.html#src.utils.gaussian_kernel">gaussian_kernel() (in module src.utils)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.utils.gaussian_kernel.html#toy.utils.gaussian_kernel">(in module toy.utils)</a>, <a href="documentation/_autosummary/toy.utils.html#toy.utils.gaussian_kernel">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseFrozenLLM.html#src.dataset.base.BaseFrozenLLM.generate_output_sentence">generate_output_sentence() (src.dataset.base.BaseFrozenLLM method)</a>, <a href="documentation/_autosummary/dataset/src.dataset.base.html#src.dataset.base.BaseFrozenLLM.generate_output_sentence">[1]</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.frozen_llm.html#src.dataset.frozen_llm.AutoFrozenLLM.generate_output_sentence">(src.dataset.frozen_llm.AutoFrozenLLM method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.get_buffer">get_buffer() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.get_buffer">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.get_buffer">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.get_buffer">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.get_buffer">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.get_buffer">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.get_buffer">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.get_buffer">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.get_buffer">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.get_buffer">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.get_buffer">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.get_buffer">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.get_buffer">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.get_buffer">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.get_buffer">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.get_extra_state">get_extra_state() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.get_extra_state">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.get_extra_state">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.get_extra_state">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.get_extra_state">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.get_extra_state">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.get_extra_state">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.get_extra_state">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.get_extra_state">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.get_extra_state">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.get_extra_state">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.get_extra_state">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.get_extra_state">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.get_extra_state">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.get_extra_state">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.get_parameter">get_parameter() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.get_parameter">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.get_parameter">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.get_parameter">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.get_parameter">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.get_parameter">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.get_parameter">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.get_parameter">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.get_parameter">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.get_parameter">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.get_parameter">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.get_parameter">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.get_parameter">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.get_parameter">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.get_parameter">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.get_submodule">get_submodule() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.get_submodule">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.get_submodule">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.get_submodule">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.get_submodule">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.get_submodule">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.get_submodule">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.get_submodule">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.get_submodule">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.get_submodule">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.get_submodule">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.get_submodule">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.get_submodule">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.get_submodule">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.get_submodule">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.EpsilonGreedyPolicy.greedy_action">greedy_action() (src.policy.policy.EpsilonGreedyPolicy method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.policy.EpsilonGreedyPolicy.html#toy.policy.policy.EpsilonGreedyPolicy.greedy_action">(toy.policy.policy.EpsilonGreedyPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.EpsilonGreedyPolicy.greedy_action">[1]</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="H">H</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.half">half() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.half">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.half">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.half">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.half">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.half">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.half">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.half">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.half">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.half">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.half">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.half">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.half">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.half">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.half">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.KernelPolicyLearner.hybrid_policy_gradient">hybrid_policy_gradient() (src.opl.policy_learner.KernelPolicyLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.PolicyLearner.hybrid_policy_gradient">(src.opl.policy_learner.PolicyLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.KernelPolicyLearner.html#toy.opl.policy_learner.KernelPolicyLearner.hybrid_policy_gradient">(toy.opl.policy_learner.KernelPolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.KernelPolicyLearner.hybrid_policy_gradient">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.PolicyLearner.html#toy.opl.policy_learner.PolicyLearner.hybrid_policy_gradient">(toy.opl.policy_learner.PolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.PolicyLearner.hybrid_policy_gradient">[1]</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="I">I</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.KernelPolicyLearner.importance_sampling_based_policy_gradient">importance_sampling_based_policy_gradient() (src.opl.policy_learner.KernelPolicyLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.PolicyLearner.importance_sampling_based_policy_gradient">(src.opl.policy_learner.PolicyLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.KernelPolicyLearner.html#toy.opl.policy_learner.KernelPolicyLearner.importance_sampling_based_policy_gradient">(toy.opl.policy_learner.KernelPolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.KernelPolicyLearner.importance_sampling_based_policy_gradient">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.PolicyLearner.html#toy.opl.policy_learner.PolicyLearner.importance_sampling_based_policy_gradient">(toy.opl.policy_learner.PolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.PolicyLearner.importance_sampling_based_policy_gradient">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.ipu">ipu() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.ipu">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.ipu">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.ipu">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.ipu">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.ipu">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.ipu">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.ipu">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.ipu">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.ipu">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.ipu">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.ipu">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.ipu">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.ipu">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.ipu">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="K">K</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.KernelMarginalDensityEstimator">KernelMarginalDensityEstimator (class in src.policy.model)</a>
</li>
      <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.KernelPolicyLearner">KernelPolicyLearner (class in src.opl.policy_learner)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.KernelPolicyLearner.html#toy.opl.policy_learner.KernelPolicyLearner">(class in toy.opl.policy_learner)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.KernelPolicyLearner">[1]</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering">KmeansActionClustering (class in toy.policy.model)</a>, <a href="documentation/_autosummary/toy.policy.model.html#toy.policy.model.KmeansActionClustering">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.KmeansPromptClustering">KmeansPromptClustering (class in src.policy.model)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="L">L</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.opl.behavior_cloning.html#src.opl.behavior_cloning.BehaviorCloningLearner.load">load() (src.opl.behavior_cloning.BehaviorCloningLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.marginal_learner.html#src.opl.marginal_learner.MarginalDensityLearner.load">(src.opl.marginal_learner.MarginalDensityLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.KernelPolicyLearner.load">(src.opl.policy_learner.KernelPolicyLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.PolicyLearner.load">(src.opl.policy_learner.PolicyLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.PromptRewardLearner.load">(src.opl.reward_learner.PromptRewardLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.SentenceRewardLearner.load">(src.opl.reward_learner.SentenceRewardLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.behavior_cloning.BehaviorCloningLearner.html#toy.opl.behavior_cloning.BehaviorCloningLearner.load">(toy.opl.behavior_cloning.BehaviorCloningLearner method)</a>, <a href="documentation/_autosummary/toy.opl.behavior_cloning.html#toy.opl.behavior_cloning.BehaviorCloningLearner.load">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.marginal_learner.MarginalDensityLearner.html#toy.opl.marginal_learner.MarginalDensityLearner.load">(toy.opl.marginal_learner.MarginalDensityLearner method)</a>, <a href="documentation/_autosummary/toy.opl.marginal_learner.html#toy.opl.marginal_learner.MarginalDensityLearner.load">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.KernelPolicyLearner.html#toy.opl.policy_learner.KernelPolicyLearner.load">(toy.opl.policy_learner.KernelPolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.KernelPolicyLearner.load">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.PolicyLearner.html#toy.opl.policy_learner.PolicyLearner.load">(toy.opl.policy_learner.PolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.PolicyLearner.load">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.ActionRewardLearner.html#toy.opl.reward_learner.ActionRewardLearner.load">(toy.opl.reward_learner.ActionRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.ActionRewardLearner.load">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.OutputRewardLearner.html#toy.opl.reward_learner.OutputRewardLearner.load">(toy.opl.reward_learner.OutputRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.OutputRewardLearner.load">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.load_state_dict">load_state_dict() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.load_state_dict">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.load_state_dict">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.load_state_dict">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.load_state_dict">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.load_state_dict">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.load_state_dict">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.load_state_dict">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.load_state_dict">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.load_state_dict">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.load_state_dict">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.load_state_dict">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.load_state_dict">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.load_state_dict">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.load_state_dict">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="M">M</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.opl.marginal_learner.html#src.opl.marginal_learner.MarginalDensityLearner">MarginalDensityLearner (class in src.opl.marginal_learner)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.marginal_learner.MarginalDensityLearner.html#toy.opl.marginal_learner.MarginalDensityLearner">(class in toy.opl.marginal_learner)</a>, <a href="documentation/_autosummary/toy.opl.marginal_learner.html#toy.opl.marginal_learner.MarginalDensityLearner">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.MixtureOfGaussianCandidateActionsGenerator.html#toy.dataset.function.MixtureOfGaussianCandidateActionsGenerator">MixtureOfGaussianCandidateActionsGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.MixtureOfGaussianCandidateActionsGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.PolicyLearner.model_based_policy_gradient">model_based_policy_gradient() (src.opl.policy_learner.PolicyLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.PolicyLearner.html#toy.opl.policy_learner.PolicyLearner.model_based_policy_gradient">(toy.opl.policy_learner.PolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.PolicyLearner.model_based_policy_gradient">[1]</a>
</li>
      </ul></li>
      <li>
    module

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.base.html#module-src.dataset.base">src.dataset.base</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.benchmark.html#module-src.dataset.benchmark">src.dataset.benchmark</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.frozen_llm.html#module-src.dataset.frozen_llm">src.dataset.frozen_llm</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.function.html#module-src.dataset.function">src.dataset.function</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.prompt_formatter.html#module-src.dataset.prompt_formatter">src.dataset.prompt_formatter</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.html#module-src.dataset.reward_simulator">src.dataset.reward_simulator</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.behavior_cloning.html#module-src.opl.behavior_cloning">src.opl.behavior_cloning</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.dataset.html#module-src.opl.dataset">src.opl.dataset</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.marginal_learner.html#module-src.opl.marginal_learner">src.opl.marginal_learner</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#module-src.opl.policy_learner">src.opl.policy_learner</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#module-src.opl.reward_learner">src.opl.reward_learner</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.base.html#module-src.policy.base">src.policy.base</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.model.html#module-src.policy.model">src.policy.model</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#module-src.policy.policy">src.policy.policy</a>
</li>
        <li><a href="documentation/_autosummary/src.utils.html#module-src.utils">src.utils</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.html#module-toy.dataset.function">toy.dataset.function</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.synthetic.html#module-toy.dataset.synthetic">toy.dataset.synthetic</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.behavior_cloning.html#module-toy.opl.behavior_cloning">toy.opl.behavior_cloning</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.marginal_learner.html#module-toy.opl.marginal_learner">toy.opl.marginal_learner</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.html#module-toy.opl.policy_learner">toy.opl.policy_learner</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.html#module-toy.opl.reward_learner">toy.opl.reward_learner</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.html#module-toy.policy.base">toy.policy.base</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.html#module-toy.policy.model">toy.policy.model</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.html#module-toy.policy.policy">toy.policy.policy</a>
</li>
        <li><a href="documentation/_autosummary/toy.utils.html#module-toy.utils">toy.utils</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.modules">modules() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.modules">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.modules">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.modules">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.modules">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.modules">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.modules">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.modules">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.modules">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.modules">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.modules">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.modules">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.modules">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.modules">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.modules">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.prompt_formatter.html#src.dataset.prompt_formatter.MovielensPromptFormatter">MovielensPromptFormatter (class in src.dataset.prompt_formatter)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="N">N</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.named_buffers">named_buffers() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.named_buffers">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.named_buffers">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.named_buffers">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.named_buffers">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.named_buffers">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.named_buffers">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.named_buffers">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.named_buffers">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.named_buffers">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.named_buffers">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.named_buffers">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.named_buffers">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.named_buffers">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.named_buffers">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.named_children">named_children() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.named_children">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.named_children">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.named_children">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.named_children">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.named_children">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.named_children">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.named_children">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.named_children">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.named_children">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.named_children">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.named_children">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.named_children">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.named_children">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.named_children">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.named_modules">named_modules() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.named_modules">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.named_modules">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.named_modules">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.named_modules">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.named_modules">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.named_modules">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.named_modules">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.named_modules">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.named_modules">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.named_modules">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.named_modules">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.named_modules">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.named_modules">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.named_modules">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.named_parameters">named_parameters() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.named_parameters">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.named_parameters">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.named_parameters">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.named_parameters">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.named_parameters">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.named_parameters">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.named_parameters">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.named_parameters">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.named_parameters">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.named_parameters">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.named_parameters">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.named_parameters">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.named_parameters">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.named_parameters">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy">NeuralActionPolicy (class in toy.policy.model)</a>, <a href="documentation/_autosummary/toy.policy.model.html#toy.policy.model.NeuralActionPolicy">[1]</a>
</li>
      <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor">NeuralActionRewardPredictor (class in toy.policy.model)</a>, <a href="documentation/_autosummary/toy.policy.model.html#toy.policy.model.NeuralActionRewardPredictor">[1]</a>
</li>
      <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy">NeuralClusterPolicy (class in toy.policy.model)</a>, <a href="documentation/_autosummary/toy.policy.model.html#toy.policy.model.NeuralClusterPolicy">[1]</a>
</li>
      <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator">NeuralMarginalDensityEstimator (class in toy.policy.model)</a>, <a href="documentation/_autosummary/toy.policy.model.html#toy.policy.model.NeuralMarginalDensityEstimator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor">NeuralOutputRewardPredictor (class in toy.policy.model)</a>, <a href="documentation/_autosummary/toy.policy.model.html#toy.policy.model.NeuralOutputRewardPredictor">[1]</a>
</li>
  </ul></td>
</tr></table>

<h2 id="O">O</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.opl.behavior_cloning.html#src.opl.behavior_cloning.BehaviorCloningLearner.offline_cloning">offline_cloning() (src.opl.behavior_cloning.BehaviorCloningLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.PromptRewardLearner.offline_cloning">(src.opl.reward_learner.PromptRewardLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.behavior_cloning.BehaviorCloningLearner.html#toy.opl.behavior_cloning.BehaviorCloningLearner.offline_cloning">(toy.opl.behavior_cloning.BehaviorCloningLearner method)</a>, <a href="documentation/_autosummary/toy.opl.behavior_cloning.html#toy.opl.behavior_cloning.BehaviorCloningLearner.offline_cloning">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.ActionRewardLearner.html#toy.opl.reward_learner.ActionRewardLearner.offline_cloning">(toy.opl.reward_learner.ActionRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.ActionRewardLearner.offline_cloning">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.PromptRewardLearner.offline_training">offline_training() (src.opl.reward_learner.PromptRewardLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.SentenceRewardLearner.offline_training">(src.opl.reward_learner.SentenceRewardLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.ActionRewardLearner.html#toy.opl.reward_learner.ActionRewardLearner.offline_training">(toy.opl.reward_learner.ActionRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.ActionRewardLearner.offline_training">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.OutputRewardLearner.html#toy.opl.reward_learner.OutputRewardLearner.offline_training">(toy.opl.reward_learner.OutputRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.OutputRewardLearner.offline_training">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.opl.behavior_cloning.html#src.opl.behavior_cloning.BehaviorCloningLearner.online_cloning">online_cloning() (src.opl.behavior_cloning.BehaviorCloningLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.PromptRewardLearner.online_cloning">(src.opl.reward_learner.PromptRewardLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.behavior_cloning.BehaviorCloningLearner.html#toy.opl.behavior_cloning.BehaviorCloningLearner.online_cloning">(toy.opl.behavior_cloning.BehaviorCloningLearner method)</a>, <a href="documentation/_autosummary/toy.opl.behavior_cloning.html#toy.opl.behavior_cloning.BehaviorCloningLearner.online_cloning">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.ActionRewardLearner.html#toy.opl.reward_learner.ActionRewardLearner.online_cloning">(toy.opl.reward_learner.ActionRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.ActionRewardLearner.online_cloning">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.PolicyLearner.online_policy_gradient">online_policy_gradient() (src.opl.policy_learner.PolicyLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.PolicyLearner.html#toy.opl.policy_learner.PolicyLearner.online_policy_gradient">(toy.opl.policy_learner.PolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.PolicyLearner.online_policy_gradient">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.PromptRewardLearner.online_training">online_training() (src.opl.reward_learner.PromptRewardLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.SentenceRewardLearner.online_training">(src.opl.reward_learner.SentenceRewardLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.ActionRewardLearner.html#toy.opl.reward_learner.ActionRewardLearner.online_training">(toy.opl.reward_learner.ActionRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.ActionRewardLearner.online_training">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.OutputRewardLearner.html#toy.opl.reward_learner.OutputRewardLearner.online_training">(toy.opl.reward_learner.OutputRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.OutputRewardLearner.online_training">[1]</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.opl.behavior_cloning.html#src.opl.behavior_cloning.BehaviorCloningLearner.optimizer">optimizer (src.opl.behavior_cloning.BehaviorCloningLearner attribute)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.marginal_learner.html#src.opl.marginal_learner.MarginalDensityLearner.optimizer">(src.opl.marginal_learner.MarginalDensityLearner attribute)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.KernelPolicyLearner.optimizer">(src.opl.policy_learner.KernelPolicyLearner attribute)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.PolicyLearner.optimizer">(src.opl.policy_learner.PolicyLearner attribute)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.PromptRewardLearner.optimizer">(src.opl.reward_learner.PromptRewardLearner attribute)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.SentenceRewardLearner.optimizer">(src.opl.reward_learner.SentenceRewardLearner attribute)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.behavior_cloning.BehaviorCloningLearner.html#toy.opl.behavior_cloning.BehaviorCloningLearner.optimizer">(toy.opl.behavior_cloning.BehaviorCloningLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.behavior_cloning.html#toy.opl.behavior_cloning.BehaviorCloningLearner.optimizer">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.marginal_learner.MarginalDensityLearner.html#toy.opl.marginal_learner.MarginalDensityLearner.optimizer">(toy.opl.marginal_learner.MarginalDensityLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.marginal_learner.html#toy.opl.marginal_learner.MarginalDensityLearner.optimizer">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.KernelPolicyLearner.html#toy.opl.policy_learner.KernelPolicyLearner.optimizer">(toy.opl.policy_learner.KernelPolicyLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.KernelPolicyLearner.optimizer">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.PolicyLearner.html#toy.opl.policy_learner.PolicyLearner.optimizer">(toy.opl.policy_learner.PolicyLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.PolicyLearner.optimizer">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.ActionRewardLearner.html#toy.opl.reward_learner.ActionRewardLearner.optimizer">(toy.opl.reward_learner.ActionRewardLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.ActionRewardLearner.optimizer">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.OutputRewardLearner.html#toy.opl.reward_learner.OutputRewardLearner.optimizer">(toy.opl.reward_learner.OutputRewardLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.OutputRewardLearner.optimizer">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/toy.opl.reward_learner.OutputRewardLearner.html#toy.opl.reward_learner.OutputRewardLearner">OutputRewardLearner (class in toy.opl.reward_learner)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.OutputRewardLearner">[1]</a>
</li>
  </ul></td>
</tr></table>

<h2 id="P">P</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.parameters">parameters() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.parameters">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.parameters">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.parameters">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.parameters">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.parameters">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.parameters">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.parameters">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.parameters">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.parameters">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.parameters">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.parameters">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.parameters">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.parameters">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.parameters">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.PolicyLearner">PolicyLearner (class in src.opl.policy_learner)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.PolicyLearner.html#toy.opl.policy_learner.PolicyLearner">(class in toy.opl.policy_learner)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.PolicyLearner">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.PowerAuxiliaryOutputGenerator.html#toy.dataset.function.PowerAuxiliaryOutputGenerator">PowerAuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.PowerAuxiliaryOutputGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePolicy.predict_policy_value">predict_policy_value() (src.policy.base.BasePolicy method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptPolicyModel.predict_policy_value">(src.policy.base.BasePromptPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.EpsilonGreedyPolicy.predict_policy_value">(src.policy.policy.EpsilonGreedyPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.SoftmaxPolicy.predict_policy_value">(src.policy.policy.SoftmaxPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.TwoStagePolicy.predict_policy_value">(src.policy.policy.TwoStagePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.UniformRandomPolicy.predict_policy_value">(src.policy.policy.UniformRandomPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.predict_policy_value">(toy.policy.base.BaseActionPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionPolicyModel.predict_policy_value">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BasePolicy.html#toy.policy.base.BasePolicy.predict_policy_value">(toy.policy.base.BasePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BasePolicy.predict_policy_value">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.predict_policy_value">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.EpsilonGreedyPolicy.html#toy.policy.policy.EpsilonGreedyPolicy.predict_policy_value">(toy.policy.policy.EpsilonGreedyPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.EpsilonGreedyPolicy.predict_policy_value">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.SoftmaxPolicy.html#toy.policy.policy.SoftmaxPolicy.predict_policy_value">(toy.policy.policy.SoftmaxPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.SoftmaxPolicy.predict_policy_value">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.TwoStagePolicy.html#toy.policy.policy.TwoStagePolicy.predict_policy_value">(toy.policy.policy.TwoStagePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.TwoStagePolicy.predict_policy_value">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.UniformRandomPolicy.html#toy.policy.policy.UniformRandomPolicy.predict_policy_value">(toy.policy.policy.UniformRandomPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.UniformRandomPolicy.predict_policy_value">[1]</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptRewardModel.predict_value">predict_value() (src.policy.base.BasePromptRewardModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseSentenceRewardModel.predict_value">(src.policy.base.BaseSentenceRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.predict_value">(toy.policy.base.BaseActionRewardModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionRewardModel.predict_value">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.predict_value">(toy.policy.base.BaseOutputRewardModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseOutputRewardModel.predict_value">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.predict_value">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.predict_value">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptRewardModel.predict_values">predict_values() (src.policy.base.BasePromptRewardModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseSentenceRewardModel.predict_values">(src.policy.base.BaseSentenceRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.predict_values">(toy.policy.base.BaseActionRewardModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionRewardModel.predict_values">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.predict_values">(toy.policy.base.BaseOutputRewardModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseOutputRewardModel.predict_values">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.predict_values">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.predict_values">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.PromptPolicy">PromptPolicy (class in src.policy.model)</a>
</li>
      <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.PromptRewardLearner">PromptRewardLearner (class in src.opl.reward_learner)</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.PromptRewardPredictor">PromptRewardPredictor (class in src.policy.model)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="R">R</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.opl.behavior_cloning.html#src.opl.behavior_cloning.BehaviorCloningLearner.random_state">random_state (src.opl.behavior_cloning.BehaviorCloningLearner attribute)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.marginal_learner.html#src.opl.marginal_learner.MarginalDensityLearner.random_state">(src.opl.marginal_learner.MarginalDensityLearner attribute)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.KernelPolicyLearner.random_state">(src.opl.policy_learner.KernelPolicyLearner attribute)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.PolicyLearner.random_state">(src.opl.policy_learner.PolicyLearner attribute)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.PromptRewardLearner.random_state">(src.opl.reward_learner.PromptRewardLearner attribute)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.SentenceRewardLearner.random_state">(src.opl.reward_learner.SentenceRewardLearner attribute)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.behavior_cloning.BehaviorCloningLearner.html#toy.opl.behavior_cloning.BehaviorCloningLearner.random_state">(toy.opl.behavior_cloning.BehaviorCloningLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.behavior_cloning.html#toy.opl.behavior_cloning.BehaviorCloningLearner.random_state">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.marginal_learner.MarginalDensityLearner.html#toy.opl.marginal_learner.MarginalDensityLearner.random_state">(toy.opl.marginal_learner.MarginalDensityLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.marginal_learner.html#toy.opl.marginal_learner.MarginalDensityLearner.random_state">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.KernelPolicyLearner.html#toy.opl.policy_learner.KernelPolicyLearner.random_state">(toy.opl.policy_learner.KernelPolicyLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.KernelPolicyLearner.random_state">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.PolicyLearner.html#toy.opl.policy_learner.PolicyLearner.random_state">(toy.opl.policy_learner.PolicyLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.PolicyLearner.random_state">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.ActionRewardLearner.html#toy.opl.reward_learner.ActionRewardLearner.random_state">(toy.opl.reward_learner.ActionRewardLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.ActionRewardLearner.random_state">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.OutputRewardLearner.html#toy.opl.reward_learner.OutputRewardLearner.random_state">(toy.opl.reward_learner.OutputRewardLearner attribute)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.OutputRewardLearner.random_state">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.RationalAuxiliaryOutputGenerator.html#toy.dataset.function.RationalAuxiliaryOutputGenerator">RationalAuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.RationalAuxiliaryOutputGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.register_backward_hook">register_backward_hook() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.register_backward_hook">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.register_backward_hook">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.register_backward_hook">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.register_backward_hook">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.register_backward_hook">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.register_backward_hook">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.register_backward_hook">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.register_backward_hook">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.register_backward_hook">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.register_backward_hook">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.register_backward_hook">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.register_backward_hook">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.register_backward_hook">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.register_backward_hook">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.register_buffer">register_buffer() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.register_buffer">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.register_buffer">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.register_buffer">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.register_buffer">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.register_buffer">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.register_buffer">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.register_buffer">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.register_buffer">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.register_buffer">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.register_buffer">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.register_buffer">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.register_buffer">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.register_buffer">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.register_buffer">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.register_forward_hook">register_forward_hook() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.register_forward_hook">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.register_forward_hook">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.register_forward_hook">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.register_forward_hook">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.register_forward_hook">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.register_forward_hook">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.register_forward_hook">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.register_forward_hook">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.register_forward_hook">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.register_forward_hook">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.register_forward_hook">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.register_forward_hook">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.register_forward_hook">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.register_forward_hook">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.register_forward_pre_hook">register_forward_pre_hook() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.register_forward_pre_hook">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.register_forward_pre_hook">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.register_forward_pre_hook">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.register_forward_pre_hook">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.register_forward_pre_hook">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.register_forward_pre_hook">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.register_forward_pre_hook">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.register_forward_pre_hook">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.register_forward_pre_hook">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.register_forward_pre_hook">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.register_forward_pre_hook">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.register_forward_pre_hook">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.register_forward_pre_hook">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.register_forward_pre_hook">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.register_full_backward_hook">register_full_backward_hook() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.register_full_backward_hook">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.register_full_backward_hook">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.register_full_backward_hook">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.register_full_backward_hook">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.register_full_backward_hook">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.register_full_backward_hook">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.register_full_backward_hook">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.register_full_backward_hook">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.register_full_backward_hook">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.register_full_backward_hook">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.register_full_backward_hook">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.register_full_backward_hook">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.register_full_backward_hook">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.register_full_backward_hook">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.register_full_backward_pre_hook">register_full_backward_pre_hook() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.register_full_backward_pre_hook">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.register_full_backward_pre_hook">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.register_full_backward_pre_hook">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.register_full_backward_pre_hook">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.register_full_backward_pre_hook">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.register_full_backward_pre_hook">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.register_full_backward_pre_hook">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.register_full_backward_pre_hook">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.register_full_backward_pre_hook">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.register_full_backward_pre_hook">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.register_full_backward_pre_hook">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.register_full_backward_pre_hook">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.register_full_backward_pre_hook">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.register_full_backward_pre_hook">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.register_load_state_dict_post_hook">register_load_state_dict_post_hook() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.register_load_state_dict_post_hook">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.register_load_state_dict_post_hook">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.register_load_state_dict_post_hook">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.register_load_state_dict_post_hook">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.register_load_state_dict_post_hook">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.register_load_state_dict_post_hook">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.register_load_state_dict_post_hook">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.register_load_state_dict_post_hook">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.register_load_state_dict_post_hook">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.register_load_state_dict_post_hook">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.register_load_state_dict_post_hook">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.register_load_state_dict_post_hook">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.register_load_state_dict_post_hook">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.register_load_state_dict_post_hook">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.register_module">register_module() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.register_module">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.register_module">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.register_module">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.register_module">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.register_module">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.register_module">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.register_module">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.register_module">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.register_module">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.register_module">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.register_module">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.register_module">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.register_module">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.register_module">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.register_parameter">register_parameter() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.register_parameter">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.register_parameter">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.register_parameter">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.register_parameter">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.register_parameter">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.register_parameter">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.register_parameter">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.register_parameter">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.register_parameter">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.register_parameter">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.register_parameter">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.register_parameter">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.register_parameter">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.register_parameter">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.register_state_dict_pre_hook">register_state_dict_pre_hook() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.register_state_dict_pre_hook">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.register_state_dict_pre_hook">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.register_state_dict_pre_hook">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.register_state_dict_pre_hook">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.register_state_dict_pre_hook">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.register_state_dict_pre_hook">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.register_state_dict_pre_hook">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.register_state_dict_pre_hook">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.register_state_dict_pre_hook">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.register_state_dict_pre_hook">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.register_state_dict_pre_hook">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.register_state_dict_pre_hook">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.register_state_dict_pre_hook">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.register_state_dict_pre_hook">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.requires_grad_">requires_grad_() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.requires_grad_">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.requires_grad_">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.requires_grad_">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.requires_grad_">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.requires_grad_">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.requires_grad_">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.requires_grad_">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.requires_grad_">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.requires_grad_">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.requires_grad_">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.requires_grad_">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.requires_grad_">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.requires_grad_">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.requires_grad_">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusteringModel.retrieve_candidate_actions">retrieve_candidate_actions() (src.policy.base.BaseClusteringModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.retrieve_candidate_actions">(toy.policy.base.BaseClusteringModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusteringModel.retrieve_candidate_actions">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.retrieve_candidate_actions">(toy.policy.model.KmeansActionClustering method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusteringModel.retrieve_candidate_actions_for_all_clusters">retrieve_candidate_actions_for_all_clusters() (src.policy.base.BaseClusteringModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.retrieve_candidate_actions_for_all_clusters">(toy.policy.base.BaseClusteringModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusteringModel.retrieve_candidate_actions_for_all_clusters">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.retrieve_candidate_actions_for_all_clusters">(toy.policy.model.KmeansActionClustering method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusteringModel.retrieve_cluster">retrieve_cluster() (src.policy.base.BaseClusteringModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.KmeansPromptClustering.retrieve_cluster">(src.policy.model.KmeansPromptClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.retrieve_cluster">(toy.policy.base.BaseClusteringModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusteringModel.retrieve_cluster">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.retrieve_cluster">(toy.policy.model.KmeansActionClustering method)</a>, <a href="documentation/_autosummary/toy.policy.model.html#toy.policy.model.KmeansActionClustering.retrieve_cluster">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusteringModel.retrieve_cluster_center">retrieve_cluster_center() (src.policy.base.BaseClusteringModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.retrieve_cluster_center">(toy.policy.base.BaseClusteringModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusteringModel.retrieve_cluster_center">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.retrieve_cluster_center">(toy.policy.model.KmeansActionClustering method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusteringModel.retrieve_cluster_centers">retrieve_cluster_centers() (src.policy.base.BaseClusteringModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.retrieve_cluster_centers">(toy.policy.base.BaseClusteringModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusteringModel.retrieve_cluster_centers">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.retrieve_cluster_centers">(toy.policy.model.KmeansActionClustering method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.RewardSimulator.html#toy.dataset.function.RewardSimulator">RewardSimulator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.RewardSimulator">[1]</a>
</li>
  </ul></td>
</tr></table>

<h2 id="S">S</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusterPolicyModel.sample_action">sample_action() (src.policy.base.BaseClusterPolicyModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePolicy.sample_action">(src.policy.base.BasePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptPolicyModel.sample_action">(src.policy.base.BasePromptPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.EpsilonGreedyPolicy.sample_action">(src.policy.policy.EpsilonGreedyPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.SoftmaxPolicy.sample_action">(src.policy.policy.SoftmaxPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.TwoStagePolicy.sample_action">(src.policy.policy.TwoStagePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.UniformRandomPolicy.sample_action">(src.policy.policy.UniformRandomPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.sample_action">(toy.policy.base.BaseActionPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionPolicyModel.sample_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.sample_action">(toy.policy.base.BaseClusterPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusterPolicyModel.sample_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BasePolicy.html#toy.policy.base.BasePolicy.sample_action">(toy.policy.base.BasePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BasePolicy.sample_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.sample_action">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.sample_action">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.EpsilonGreedyPolicy.html#toy.policy.policy.EpsilonGreedyPolicy.sample_action">(toy.policy.policy.EpsilonGreedyPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.EpsilonGreedyPolicy.sample_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.SoftmaxPolicy.html#toy.policy.policy.SoftmaxPolicy.sample_action">(toy.policy.policy.SoftmaxPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.SoftmaxPolicy.sample_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.TwoStagePolicy.html#toy.policy.policy.TwoStagePolicy.sample_action">(toy.policy.policy.TwoStagePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.TwoStagePolicy.sample_action">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.UniformRandomPolicy.html#toy.policy.policy.UniformRandomPolicy.sample_action">(toy.policy.policy.UniformRandomPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.UniformRandomPolicy.sample_action">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusterPolicyModel.sample_action_and_output_prob">sample_action_and_output_prob() (src.policy.base.BaseClusterPolicyModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePolicy.sample_action_and_output_prob">(src.policy.base.BasePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptPolicyModel.sample_action_and_output_prob">(src.policy.base.BasePromptPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.EpsilonGreedyPolicy.sample_action_and_output_prob">(src.policy.policy.EpsilonGreedyPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.SoftmaxPolicy.sample_action_and_output_prob">(src.policy.policy.SoftmaxPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.TwoStagePolicy.sample_action_and_output_prob">(src.policy.policy.TwoStagePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.UniformRandomPolicy.sample_action_and_output_prob">(src.policy.policy.UniformRandomPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.sample_action_and_output_prob">(toy.policy.base.BaseActionPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionPolicyModel.sample_action_and_output_prob">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.sample_action_and_output_prob">(toy.policy.base.BaseClusterPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusterPolicyModel.sample_action_and_output_prob">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BasePolicy.html#toy.policy.base.BasePolicy.sample_action_and_output_prob">(toy.policy.base.BasePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BasePolicy.sample_action_and_output_prob">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.sample_action_and_output_prob">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.sample_action_and_output_prob">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.EpsilonGreedyPolicy.html#toy.policy.policy.EpsilonGreedyPolicy.sample_action_and_output_prob">(toy.policy.policy.EpsilonGreedyPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.EpsilonGreedyPolicy.sample_action_and_output_prob">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.SoftmaxPolicy.html#toy.policy.policy.SoftmaxPolicy.sample_action_and_output_prob">(toy.policy.policy.SoftmaxPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.SoftmaxPolicy.sample_action_and_output_prob">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.TwoStagePolicy.html#toy.policy.policy.TwoStagePolicy.sample_action_and_output_prob">(toy.policy.policy.TwoStagePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.TwoStagePolicy.sample_action_and_output_prob">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.UniformRandomPolicy.html#toy.policy.policy.UniformRandomPolicy.sample_action_and_output_prob">(toy.policy.policy.UniformRandomPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.UniformRandomPolicy.sample_action_and_output_prob">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.AuxiliaryOutputGenerator.html#toy.dataset.function.AuxiliaryOutputGenerator.sample_auxiliary_output">sample_auxiliary_output() (toy.dataset.function.AuxiliaryOutputGenerator method)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.AuxiliaryOutputGenerator.sample_auxiliary_output">[1]</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ConfoundedAuxiliaryOutputGenerator.html#toy.dataset.function.ConfoundedAuxiliaryOutputGenerator.sample_auxiliary_output">(toy.dataset.function.ConfoundedAuxiliaryOutputGenerator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ConfoundedExponentialAuxiliaryOutputGenerator.html#toy.dataset.function.ConfoundedExponentialAuxiliaryOutputGenerator.sample_auxiliary_output">(toy.dataset.function.ConfoundedExponentialAuxiliaryOutputGenerator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ConfoundedPowerAuxiliaryOutputGenerator.html#toy.dataset.function.ConfoundedPowerAuxiliaryOutputGenerator.sample_auxiliary_output">(toy.dataset.function.ConfoundedPowerAuxiliaryOutputGenerator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ConfoundedRationalAuxiliaryOutputGenerator.html#toy.dataset.function.ConfoundedRationalAuxiliaryOutputGenerator.sample_auxiliary_output">(toy.dataset.function.ConfoundedRationalAuxiliaryOutputGenerator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ConfoundedTrigonometricAuxiliaryOutputGenerator.html#toy.dataset.function.ConfoundedTrigonometricAuxiliaryOutputGenerator.sample_auxiliary_output">(toy.dataset.function.ConfoundedTrigonometricAuxiliaryOutputGenerator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ExponentialAuxiliaryOutputGenerator.html#toy.dataset.function.ExponentialAuxiliaryOutputGenerator.sample_auxiliary_output">(toy.dataset.function.ExponentialAuxiliaryOutputGenerator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.PowerAuxiliaryOutputGenerator.html#toy.dataset.function.PowerAuxiliaryOutputGenerator.sample_auxiliary_output">(toy.dataset.function.PowerAuxiliaryOutputGenerator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.RationalAuxiliaryOutputGenerator.html#toy.dataset.function.RationalAuxiliaryOutputGenerator.sample_auxiliary_output">(toy.dataset.function.RationalAuxiliaryOutputGenerator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.SigmoidAuxiliaryOutputGenerator.html#toy.dataset.function.SigmoidAuxiliaryOutputGenerator.sample_auxiliary_output">(toy.dataset.function.SigmoidAuxiliaryOutputGenerator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.TrigonometricAuxiliaryOutputGenerator.html#toy.dataset.function.TrigonometricAuxiliaryOutputGenerator.sample_auxiliary_output">(toy.dataset.function.TrigonometricAuxiliaryOutputGenerator method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusteringModel.sample_clustering">sample_clustering() (src.policy.base.BaseClusteringModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.KmeansPromptClustering.sample_clustering">(src.policy.model.KmeansPromptClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.sample_clustering">(toy.policy.base.BaseClusteringModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusteringModel.sample_clustering">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.sample_clustering">(toy.policy.model.KmeansActionClustering method)</a>, <a href="documentation/_autosummary/toy.policy.model.html#toy.policy.model.KmeansActionClustering.sample_clustering">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.function.DefaultContextQueryLoader.html#src.dataset.function.DefaultContextQueryLoader.sample_context_and_query">sample_context_and_query() (src.dataset.function.DefaultContextQueryLoader method)</a>, <a href="documentation/_autosummary/dataset/src.dataset.function.html#src.dataset.function.DefaultContextQueryLoader.sample_context_and_query">[1]</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.ContextQueryGenerator.html#toy.dataset.function.ContextQueryGenerator.sample_context_and_query">(toy.dataset.function.ContextQueryGenerator method)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.ContextQueryGenerator.sample_context_and_query">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.benchmark.SemiSyntheticDataset.html#src.dataset.benchmark.SemiSyntheticDataset.sample_dataset">sample_dataset() (src.dataset.benchmark.SemiSyntheticDataset method)</a>, <a href="documentation/_autosummary/dataset/src.dataset.benchmark.html#src.dataset.benchmark.SemiSyntheticDataset.sample_dataset">[1]</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.synthetic.SyntheticDataset.html#toy.dataset.synthetic.SyntheticDataset.sample_dataset">(toy.dataset.synthetic.SyntheticDataset method)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.synthetic.html#toy.dataset.synthetic.SyntheticDataset.sample_dataset">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BaseClusterPolicyModel.sample_multiple_actions">sample_multiple_actions() (src.policy.base.BaseClusterPolicyModel method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePolicy.sample_multiple_actions">(src.policy.base.BasePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.base.html#src.policy.base.BasePromptPolicyModel.sample_multiple_actions">(src.policy.base.BasePromptPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.EpsilonGreedyPolicy.sample_multiple_actions">(src.policy.policy.EpsilonGreedyPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.SoftmaxPolicy.sample_multiple_actions">(src.policy.policy.SoftmaxPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.TwoStagePolicy.sample_multiple_actions">(src.policy.policy.TwoStagePolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.UniformRandomPolicy.sample_multiple_actions">(src.policy.policy.UniformRandomPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.sample_multiple_actions">(toy.policy.base.BaseActionPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseActionPolicyModel.sample_multiple_actions">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.sample_multiple_actions">(toy.policy.base.BaseClusterPolicyModel method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BaseClusterPolicyModel.sample_multiple_actions">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BasePolicy.html#toy.policy.base.BasePolicy.sample_multiple_actions">(toy.policy.base.BasePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.base.html#toy.policy.base.BasePolicy.sample_multiple_actions">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.sample_multiple_actions">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.sample_multiple_actions">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.EpsilonGreedyPolicy.html#toy.policy.policy.EpsilonGreedyPolicy.sample_multiple_actions">(toy.policy.policy.EpsilonGreedyPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.EpsilonGreedyPolicy.sample_multiple_actions">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.SoftmaxPolicy.html#toy.policy.policy.SoftmaxPolicy.sample_multiple_actions">(toy.policy.policy.SoftmaxPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.SoftmaxPolicy.sample_multiple_actions">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.TwoStagePolicy.html#toy.policy.policy.TwoStagePolicy.sample_multiple_actions">(toy.policy.policy.TwoStagePolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.TwoStagePolicy.sample_multiple_actions">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.policy.UniformRandomPolicy.html#toy.policy.policy.UniformRandomPolicy.sample_multiple_actions">(toy.policy.policy.UniformRandomPolicy method)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.UniformRandomPolicy.sample_multiple_actions">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.benchmark.SemiSyntheticDataset.html#src.dataset.benchmark.SemiSyntheticDataset.sample_reward_given_action">sample_reward_given_action() (src.dataset.benchmark.SemiSyntheticDataset method)</a>, <a href="documentation/_autosummary/dataset/src.dataset.benchmark.html#src.dataset.benchmark.SemiSyntheticDataset.sample_reward_given_action">[1]</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.synthetic.SyntheticDataset.html#toy.dataset.synthetic.SyntheticDataset.sample_reward_given_action">(toy.dataset.synthetic.SyntheticDataset method)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.synthetic.html#toy.dataset.synthetic.SyntheticDataset.sample_reward_given_action">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.benchmark.SemiSyntheticDataset.html#src.dataset.benchmark.SemiSyntheticDataset.sample_reward_given_output">sample_reward_given_output() (src.dataset.benchmark.SemiSyntheticDataset method)</a>, <a href="documentation/_autosummary/dataset/src.dataset.benchmark.html#src.dataset.benchmark.SemiSyntheticDataset.sample_reward_given_output">[1]</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.synthetic.SyntheticDataset.html#toy.dataset.synthetic.SyntheticDataset.sample_reward_given_output">(toy.dataset.synthetic.SyntheticDataset method)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.synthetic.html#toy.dataset.synthetic.SyntheticDataset.sample_reward_given_output">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.opl.behavior_cloning.html#src.opl.behavior_cloning.BehaviorCloningLearner.save">save() (src.opl.behavior_cloning.BehaviorCloningLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.marginal_learner.html#src.opl.marginal_learner.MarginalDensityLearner.save">(src.opl.marginal_learner.MarginalDensityLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.KernelPolicyLearner.save">(src.opl.policy_learner.KernelPolicyLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.PolicyLearner.save">(src.opl.policy_learner.PolicyLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.PromptRewardLearner.save">(src.opl.reward_learner.PromptRewardLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.SentenceRewardLearner.save">(src.opl.reward_learner.SentenceRewardLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.behavior_cloning.BehaviorCloningLearner.html#toy.opl.behavior_cloning.BehaviorCloningLearner.save">(toy.opl.behavior_cloning.BehaviorCloningLearner method)</a>, <a href="documentation/_autosummary/toy.opl.behavior_cloning.html#toy.opl.behavior_cloning.BehaviorCloningLearner.save">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.marginal_learner.MarginalDensityLearner.html#toy.opl.marginal_learner.MarginalDensityLearner.save">(toy.opl.marginal_learner.MarginalDensityLearner method)</a>, <a href="documentation/_autosummary/toy.opl.marginal_learner.html#toy.opl.marginal_learner.MarginalDensityLearner.save">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.KernelPolicyLearner.html#toy.opl.policy_learner.KernelPolicyLearner.save">(toy.opl.policy_learner.KernelPolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.KernelPolicyLearner.save">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.PolicyLearner.html#toy.opl.policy_learner.PolicyLearner.save">(toy.opl.policy_learner.PolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.PolicyLearner.save">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.ActionRewardLearner.html#toy.opl.reward_learner.ActionRewardLearner.save">(toy.opl.reward_learner.ActionRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.ActionRewardLearner.save">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.OutputRewardLearner.html#toy.opl.reward_learner.OutputRewardLearner.save">(toy.opl.reward_learner.OutputRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.OutputRewardLearner.save">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.opl.behavior_cloning.html#src.opl.behavior_cloning.BehaviorCloningLearner.seed">seed() (src.opl.behavior_cloning.BehaviorCloningLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/src.opl.marginal_learner.html#src.opl.marginal_learner.MarginalDensityLearner.seed">(src.opl.marginal_learner.MarginalDensityLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.KernelPolicyLearner.seed">(src.opl.policy_learner.KernelPolicyLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#src.opl.policy_learner.PolicyLearner.seed">(src.opl.policy_learner.PolicyLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.PromptRewardLearner.seed">(src.opl.reward_learner.PromptRewardLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.SentenceRewardLearner.seed">(src.opl.reward_learner.SentenceRewardLearner method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.behavior_cloning.BehaviorCloningLearner.html#toy.opl.behavior_cloning.BehaviorCloningLearner.seed">(toy.opl.behavior_cloning.BehaviorCloningLearner method)</a>, <a href="documentation/_autosummary/toy.opl.behavior_cloning.html#toy.opl.behavior_cloning.BehaviorCloningLearner.seed">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.marginal_learner.MarginalDensityLearner.html#toy.opl.marginal_learner.MarginalDensityLearner.seed">(toy.opl.marginal_learner.MarginalDensityLearner method)</a>, <a href="documentation/_autosummary/toy.opl.marginal_learner.html#toy.opl.marginal_learner.MarginalDensityLearner.seed">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.KernelPolicyLearner.html#toy.opl.policy_learner.KernelPolicyLearner.seed">(toy.opl.policy_learner.KernelPolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.KernelPolicyLearner.seed">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.PolicyLearner.html#toy.opl.policy_learner.PolicyLearner.seed">(toy.opl.policy_learner.PolicyLearner method)</a>, <a href="documentation/_autosummary/toy.opl.policy_learner.html#toy.opl.policy_learner.PolicyLearner.seed">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.ActionRewardLearner.html#toy.opl.reward_learner.ActionRewardLearner.seed">(toy.opl.reward_learner.ActionRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.ActionRewardLearner.seed">[1]</a>
</li>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.OutputRewardLearner.html#toy.opl.reward_learner.OutputRewardLearner.seed">(toy.opl.reward_learner.OutputRewardLearner method)</a>, <a href="documentation/_autosummary/toy.opl.reward_learner.html#toy.opl.reward_learner.OutputRewardLearner.seed">[1]</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.benchmark.SemiSyntheticDataset.html#src.dataset.benchmark.SemiSyntheticDataset">SemiSyntheticDataset (class in src.dataset.benchmark)</a>, <a href="documentation/_autosummary/dataset/src.dataset.benchmark.html#src.dataset.benchmark.SemiSyntheticDataset">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.opl.reward_learner.html#src.opl.reward_learner.SentenceRewardLearner">SentenceRewardLearner (class in src.opl.reward_learner)</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.SentenceRewardPredictor">SentenceRewardPredictor (class in src.policy.model)</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.set_extra_state">set_extra_state() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.set_extra_state">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.set_extra_state">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.set_extra_state">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.set_extra_state">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.set_extra_state">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.set_extra_state">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.set_extra_state">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.set_extra_state">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.set_extra_state">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.set_extra_state">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.set_extra_state">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.set_extra_state">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.set_extra_state">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.set_extra_state">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.share_memory">share_memory() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.share_memory">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.share_memory">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.share_memory">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.share_memory">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.share_memory">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.share_memory">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.share_memory">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.share_memory">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.share_memory">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.share_memory">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.share_memory">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.share_memory">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.share_memory">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.share_memory">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.SigmoidAuxiliaryOutputGenerator.html#toy.dataset.function.SigmoidAuxiliaryOutputGenerator">SigmoidAuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.SigmoidAuxiliaryOutputGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.opl.marginal_learner.html#src.opl.marginal_learner.MarginalDensityLearner.simulation_training">simulation_training() (src.opl.marginal_learner.MarginalDensityLearner method)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.marginal_learner.MarginalDensityLearner.html#toy.opl.marginal_learner.MarginalDensityLearner.simulation_training">(toy.opl.marginal_learner.MarginalDensityLearner method)</a>, <a href="documentation/_autosummary/toy.opl.marginal_learner.html#toy.opl.marginal_learner.MarginalDensityLearner.simulation_training">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.SoftmaxPolicy">SoftmaxPolicy (class in src.policy.policy)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.policy.SoftmaxPolicy.html#toy.policy.policy.SoftmaxPolicy">(class in toy.policy.policy)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.SoftmaxPolicy">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.SparseRewardSimulator.html#toy.dataset.function.SparseRewardSimulator">SparseRewardSimulator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.SparseRewardSimulator">[1]</a>
</li>
      <li>
    src.dataset.base

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.base.html#module-src.dataset.base">module</a>
</li>
      </ul></li>
      <li>
    src.dataset.benchmark

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.benchmark.html#module-src.dataset.benchmark">module</a>
</li>
      </ul></li>
      <li>
    src.dataset.frozen_llm

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.frozen_llm.html#module-src.dataset.frozen_llm">module</a>
</li>
      </ul></li>
      <li>
    src.dataset.function

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.function.html#module-src.dataset.function">module</a>
</li>
      </ul></li>
      <li>
    src.dataset.prompt_formatter

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.prompt_formatter.html#module-src.dataset.prompt_formatter">module</a>
</li>
      </ul></li>
      <li>
    src.dataset.reward_simulator

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.html#module-src.dataset.reward_simulator">module</a>
</li>
      </ul></li>
      <li>
    src.opl.behavior_cloning

      <ul>
        <li><a href="documentation/_autosummary/src.opl.behavior_cloning.html#module-src.opl.behavior_cloning">module</a>
</li>
      </ul></li>
      <li>
    src.opl.dataset

      <ul>
        <li><a href="documentation/_autosummary/src.opl.dataset.html#module-src.opl.dataset">module</a>
</li>
      </ul></li>
      <li>
    src.opl.marginal_learner

      <ul>
        <li><a href="documentation/_autosummary/src.opl.marginal_learner.html#module-src.opl.marginal_learner">module</a>
</li>
      </ul></li>
      <li>
    src.opl.policy_learner

      <ul>
        <li><a href="documentation/_autosummary/src.opl.policy_learner.html#module-src.opl.policy_learner">module</a>
</li>
      </ul></li>
      <li>
    src.opl.reward_learner

      <ul>
        <li><a href="documentation/_autosummary/src.opl.reward_learner.html#module-src.opl.reward_learner">module</a>
</li>
      </ul></li>
      <li>
    src.policy.base

      <ul>
        <li><a href="documentation/_autosummary/src.policy.base.html#module-src.policy.base">module</a>
</li>
      </ul></li>
      <li>
    src.policy.model

      <ul>
        <li><a href="documentation/_autosummary/src.policy.model.html#module-src.policy.model">module</a>
</li>
      </ul></li>
      <li>
    src.policy.policy

      <ul>
        <li><a href="documentation/_autosummary/src.policy.policy.html#module-src.policy.policy">module</a>
</li>
      </ul></li>
      <li>
    src.utils

      <ul>
        <li><a href="documentation/_autosummary/src.utils.html#module-src.utils">module</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.state_dict">state_dict() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.state_dict">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.state_dict">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.state_dict">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.state_dict">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.state_dict">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.state_dict">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.state_dict">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.state_dict">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.state_dict">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.state_dict">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.state_dict">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.state_dict">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.state_dict">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.state_dict">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.synthetic.SyntheticDataset.html#toy.dataset.synthetic.SyntheticDataset">SyntheticDataset (class in toy.dataset.synthetic)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.synthetic.html#toy.dataset.synthetic.SyntheticDataset">[1]</a>
</li>
  </ul></td>
</tr></table>

<h2 id="T">T</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.to">to() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.to">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.to">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.to">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.to">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.to">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.to">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.to">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.to">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.to">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.to">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.to">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.to">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.to">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.to">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.utils.html#src.utils.to_device">to_device() (in module src.utils)</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.to_empty">to_empty() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.to_empty">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.to_empty">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.to_empty">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.to_empty">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.to_empty">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.to_empty">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.to_empty">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.to_empty">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.to_empty">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.to_empty">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.to_empty">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.to_empty">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.to_empty">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.to_empty">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.utils.html#src.utils.tokenize">tokenize() (in module src.utils)</a>
</li>
      <li><a href="documentation/_autosummary/src.utils.html#src.utils.torch_seed">torch_seed() (in module src.utils)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.utils.html#toy.utils.torch_seed">(in module toy.utils)</a>, <a href="documentation/_autosummary/toy.utils.torch_seed.html#toy.utils.torch_seed">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.opl.dataset.html#src.opl.dataset.TorchLoggedDataset">TorchLoggedDataset (class in src.opl.dataset)</a>
</li>
      <li>
    toy.dataset.function

      <ul>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.function.html#module-toy.dataset.function">module</a>
</li>
      </ul></li>
      <li>
    toy.dataset.synthetic

      <ul>
        <li><a href="documentation/_autosummary/dataset/toy.dataset.synthetic.html#module-toy.dataset.synthetic">module</a>
</li>
      </ul></li>
      <li>
    toy.opl.behavior_cloning

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.behavior_cloning.html#module-toy.opl.behavior_cloning">module</a>
</li>
      </ul></li>
      <li>
    toy.opl.marginal_learner

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.marginal_learner.html#module-toy.opl.marginal_learner">module</a>
</li>
      </ul></li>
      <li>
    toy.opl.policy_learner

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.policy_learner.html#module-toy.opl.policy_learner">module</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li>
    toy.opl.reward_learner

      <ul>
        <li><a href="documentation/_autosummary/toy.opl.reward_learner.html#module-toy.opl.reward_learner">module</a>
</li>
      </ul></li>
      <li>
    toy.policy.base

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.base.html#module-toy.policy.base">module</a>
</li>
      </ul></li>
      <li>
    toy.policy.model

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.model.html#module-toy.policy.model">module</a>
</li>
      </ul></li>
      <li>
    toy.policy.policy

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.policy.html#module-toy.policy.policy">module</a>
</li>
      </ul></li>
      <li>
    toy.utils

      <ul>
        <li><a href="documentation/_autosummary/toy.utils.html#module-toy.utils">module</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.train">train() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.train">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.train">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.train">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.train">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.train">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.train">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.train">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.train">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.train">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.train">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.train">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.train">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.train">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.train">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/src.policy.model.html#src.policy.model.TransformerEncoder">TransformerEncoder (class in src.policy.model)</a>
</li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator">TransformerRewardSimulator (class in src.dataset.reward_simulator)</a>, <a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.html#src.dataset.reward_simulator.TransformerRewardSimulator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/dataset/toy.dataset.function.TrigonometricAuxiliaryOutputGenerator.html#toy.dataset.function.TrigonometricAuxiliaryOutputGenerator">TrigonometricAuxiliaryOutputGenerator (class in toy.dataset.function)</a>, <a href="documentation/_autosummary/dataset/toy.dataset.function.html#toy.dataset.function.TrigonometricAuxiliaryOutputGenerator">[1]</a>
</li>
      <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.TwoStagePolicy">TwoStagePolicy (class in src.policy.policy)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.policy.TwoStagePolicy.html#toy.policy.policy.TwoStagePolicy">(class in toy.policy.policy)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.TwoStagePolicy">[1]</a>
</li>
      </ul></li>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.type">type() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.type">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.type">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.type">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.type">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.type">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.type">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.type">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.type">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.type">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.type">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.type">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.type">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.type">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.type">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="U">U</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.utils.html#src.utils.uniform_kernel">uniform_kernel() (in module src.utils)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.utils.html#toy.utils.uniform_kernel">(in module toy.utils)</a>, <a href="documentation/_autosummary/toy.utils.uniform_kernel.html#toy.utils.uniform_kernel">[1]</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/src.policy.policy.html#src.policy.policy.UniformRandomPolicy">UniformRandomPolicy (class in src.policy.policy)</a>

      <ul>
        <li><a href="documentation/_autosummary/toy.policy.policy.UniformRandomPolicy.html#toy.policy.policy.UniformRandomPolicy">(class in toy.policy.policy)</a>, <a href="documentation/_autosummary/toy.policy.policy.html#toy.policy.policy.UniformRandomPolicy">[1]</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="X">X</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.xpu">xpu() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.xpu">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.xpu">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.xpu">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.xpu">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.xpu">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.xpu">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.xpu">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.xpu">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.xpu">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.xpu">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.xpu">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.xpu">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.xpu">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.xpu">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="Z">Z</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="documentation/_autosummary/dataset/src.dataset.base.BaseRewardSimulator.html#src.dataset.base.BaseRewardSimulator.zero_grad">zero_grad() (src.dataset.base.BaseRewardSimulator method)</a>

      <ul>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.html#src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator.zero_grad">(src.dataset.reward_simulator.CollaborativeFilteringRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/dataset/src.dataset.reward_simulator.TransformerRewardSimulator.html#src.dataset.reward_simulator.TransformerRewardSimulator.zero_grad">(src.dataset.reward_simulator.TransformerRewardSimulator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionPolicyModel.html#toy.policy.base.BaseActionPolicyModel.zero_grad">(toy.policy.base.BaseActionPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseActionRewardModel.html#toy.policy.base.BaseActionRewardModel.zero_grad">(toy.policy.base.BaseActionRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusteringModel.html#toy.policy.base.BaseClusteringModel.zero_grad">(toy.policy.base.BaseClusteringModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseClusterPolicyModel.html#toy.policy.base.BaseClusterPolicyModel.zero_grad">(toy.policy.base.BaseClusterPolicyModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseKernelMarginalDensityModel.html#toy.policy.base.BaseKernelMarginalDensityModel.zero_grad">(toy.policy.base.BaseKernelMarginalDensityModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.base.BaseOutputRewardModel.html#toy.policy.base.BaseOutputRewardModel.zero_grad">(toy.policy.base.BaseOutputRewardModel method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.KmeansActionClustering.html#toy.policy.model.KmeansActionClustering.zero_grad">(toy.policy.model.KmeansActionClustering method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionPolicy.html#toy.policy.model.NeuralActionPolicy.zero_grad">(toy.policy.model.NeuralActionPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralActionRewardPredictor.html#toy.policy.model.NeuralActionRewardPredictor.zero_grad">(toy.policy.model.NeuralActionRewardPredictor method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralClusterPolicy.html#toy.policy.model.NeuralClusterPolicy.zero_grad">(toy.policy.model.NeuralClusterPolicy method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralMarginalDensityEstimator.html#toy.policy.model.NeuralMarginalDensityEstimator.zero_grad">(toy.policy.model.NeuralMarginalDensityEstimator method)</a>
</li>
        <li><a href="documentation/_autosummary/toy.policy.model.NeuralOutputRewardPredictor.html#toy.policy.model.NeuralOutputRewardPredictor.zero_grad">(toy.policy.model.NeuralOutputRewardPredictor method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>



           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Haruka Kiyohara, Yuta Saito, Daniel Cao, Thorsten Joachims.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>